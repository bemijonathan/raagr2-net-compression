{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the model and test 5 images in in validation set\n",
    "\n",
    "import torch\n",
    "from utils.load_data import BrainDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from architecture.model import load_trained_model, All_view, evaluate_dice_scores, class_dice, arrange_img, dice_coef, mean_iou\n",
    "import random\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "train_data = r\"../data\"\n",
    "val_dataset = BrainDataset(train_data, \"val\")\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 1. First create a fresh model instance\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = \u001b[43mload_trained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../model/shared/shared_dlu_model_epoch_15.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 5. Set model to evaluation mode\u001b[39;00m\n\u001b[32m      7\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/school/projects/rewrite_brain_segmentation_pytourch/src/architecture/shared_model.py:488\u001b[39m, in \u001b[36mload_trained_model\u001b[39m\u001b[34m(model_path)\u001b[39m\n\u001b[32m    486\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load a trained model from a checkpoint file\"\"\"\u001b[39;00m\n\u001b[32m    487\u001b[39m model = DLUNet(in_channels=\u001b[32m4\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m model.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[32m    490\u001b[39m model = model.to(device)\n\u001b[32m    491\u001b[39m model.eval()  \u001b[38;5;66;03m# Set to evaluation mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/school/projects/rewrite_brain_segmentation_pytourch/.venv/lib/python3.12/site-packages/torch/serialization.py:1471\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1469\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1470\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1471\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1472\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1473\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1474\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1475\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1476\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1477\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[32m   1479\u001b[39m     f_name = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/school/projects/rewrite_brain_segmentation_pytourch/.venv/lib/python3.12/site-packages/torch/serialization.py:1964\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   1962\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   1963\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1965\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1967\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/school/projects/rewrite_brain_segmentation_pytourch/.venv/lib/python3.12/site-packages/torch/serialization.py:1953\u001b[39m, in \u001b[36m_load.<locals>.UnpicklerWrapper.find_class\u001b[39m\u001b[34m(self, mod_name, name)\u001b[39m\n\u001b[32m   1951\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1952\u001b[39m mod_name = load_module_mapping.get(mod_name, mod_name)\n\u001b[32m-> \u001b[39m\u001b[32m1953\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from architecture.shared_model import DLUNet, ReASPP3, load_trained_model\n",
    "import torch\n",
    "\n",
    "# 1. First create a fresh model instance\n",
    "model = load_trained_model(\"../model/shared/shared_dlu_model_epoch_15.pth\")\n",
    "# 5. Set model to evaluation mode\n",
    "model.eval()\n",
    "print(\"Model loaded successfully and set to evaluation mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = load_trained_model(\"./model/dlu_net_model_epoch_20.pth\")\n",
    "# model = load_trained_model(\n",
    "#     # \"./model/dlu_net_model_epoch_52.pth\"\n",
    "#     # \"./model/dlu_net_model_epoch_55.pth\"\n",
    "#     # \"./model/dlu_net_model_epoch_68.pth\"\n",
    "#     \"model/dlu_net_model_epoch_2.pth\"\n",
    "\n",
    "# )\n",
    "\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample batch from the validation loader\n",
    "# next() retrieves the first item from the iterator created by iter(val_loader)\n",
    "# iter() creates an iterator from val_loader which is likely a DataLoader object\n",
    "# This gets one batch of data containing both images and masks\n",
    "import matplotlib.pyplot as plt\n",
    "val_images, val_masks = next(iter(val_loader))\n",
    "print(f\"Batch shape - Images: {val_images.shape}, Masks: {val_masks.shape}\")\n",
    "\n",
    "\n",
    "# Select a random sample from the batch\n",
    "random_idx = random.randint(0, val_images.shape[0]-1)\n",
    "\n",
    "\n",
    "print(random_idx)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get the first sample\n",
    "    sample_image = val_images[random_idx:random_idx + 1].to(device)\n",
    "    sample_mask = val_masks[random_idx:random_idx + 1].to(device)\n",
    "\n",
    "    # Get prediction\n",
    "    prediction = model(sample_image)\n",
    "    thresholded_pred = (prediction > 0.2).float()\n",
    "\n",
    "    # Use the prediction directly for dice calculation instead of calling evaluate_dice_scores\n",
    "    tc_dice = class_dice(prediction, sample_mask, 2).item()\n",
    "    ec_dice = class_dice(prediction, sample_mask, 3).item()\n",
    "    wt_dice = class_dice(prediction, sample_mask, 4).item()\n",
    "\n",
    "    print(\n",
    "        f\"Sample Dice Scores - Tumor Core: {tc_dice:.4f}, Enhancing Tumor: {ec_dice:.4f}, Whole Tumor: {wt_dice:.4f}\")\n",
    "\n",
    "# Visualize the prediction vs ground truth\n",
    "\n",
    "# Convert tensors to the right format for visualization\n",
    "sample_image_np = sample_image.cpu().numpy().transpose(\n",
    "    0, 2, 3, 1)  # [B,C,H,W] -> [B,H,W,C]\n",
    "sample_mask_np = sample_mask.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "pred_np = thresholded_pred.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "# Use the visualization functions\n",
    "GT, Pre, TC, EC, WT = arrange_img(\n",
    "    torch.from_numpy(sample_image_np),\n",
    "    torch.from_numpy(sample_mask_np),\n",
    "    torch.from_numpy(pred_np)\n",
    ")\n",
    "\n",
    "# Convert tensors to numpy for matplotlib if needed\n",
    "if isinstance(GT, torch.Tensor):\n",
    "    GT = GT.numpy()\n",
    "if isinstance(Pre, torch.Tensor):\n",
    "    Pre = Pre.numpy()\n",
    "if isinstance(TC, torch.Tensor):\n",
    "    TC = TC.numpy()\n",
    "if isinstance(EC, torch.Tensor):\n",
    "    EC = EC.numpy()\n",
    "if isinstance(WT, torch.Tensor):\n",
    "    WT = WT.numpy()\n",
    "\n",
    "# Display the results\n",
    "fig, ax = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "ax[0, 0].imshow(GT)\n",
    "ax[0, 0].set_title('Ground Truth', fontsize=15)\n",
    "ax[0, 0].axis(\"off\")\n",
    "\n",
    "ax[0, 1].imshow(Pre)\n",
    "ax[0, 1].set_title('Prediction', fontsize=15)\n",
    "ax[0, 1].axis(\"off\")\n",
    "\n",
    "ax[0, 2].imshow(TC)\n",
    "ax[0, 2].set_title(f'Tumor Core: {tc_dice:.4f}', fontsize=15)\n",
    "ax[0, 2].axis(\"off\")\n",
    "\n",
    "ax[1, 0].imshow(EC)\n",
    "ax[1, 0].set_title(f'Enhancing Tumor: {ec_dice:.4f}', fontsize=15)\n",
    "ax[1, 0].axis(\"off\")\n",
    "\n",
    "ax[1, 1].imshow(WT)\n",
    "ax[1, 1].set_title(f'Whole Tumor: {wt_dice:.4f}', fontsize=15)\n",
    "ax[1, 1].axis(\"off\")\n",
    "\n",
    "# Display original MRI (first channel)\n",
    "ax[1, 2].imshow(sample_image_np[0, :, :, 0], cmap='gray')\n",
    "ax[1, 2].set_title('Original MRI (Channel 0)', fontsize=15)\n",
    "ax[1, 2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average accuracy of the model for the entire validation set\n",
    "\n",
    "import numpy as np\n",
    "results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i in range(len(val_images)):\n",
    "        # Get the first sample\n",
    "        sample_image = val_images[i:i + 1].to(device)\n",
    "        sample_mask = val_masks[i:i + 1].to(device)\n",
    "\n",
    "        # Get prediction\n",
    "        prediction = model(sample_image)\n",
    "        thresholded_pred = (prediction > 0.2).float()\n",
    "\n",
    "        # Use the prediction directly for dice calculation instead of calling evaluate_dice_scores\n",
    "        tc_dice = class_dice(prediction, sample_mask, 2).item()\n",
    "        ec_dice = class_dice(prediction, sample_mask, 3).item()\n",
    "        wt_dice = class_dice(prediction, sample_mask, 4).item()\n",
    "\n",
    "        dice_score_main = dice_coef(prediction, sample_mask)\n",
    "        mean_iou_score = mean_iou(prediction, sample_mask)\n",
    "\n",
    "        results.append([tc_dice, ec_dice, wt_dice,\n",
    "                       dice_score_main, mean_iou_score])\n",
    "    print(\n",
    "        f\"Sample Dice Scores - Tumor Core: {tc_dice:.4f}, Enhancing Tumor: {ec_dice:.4f}, Whole Tumor: {wt_dice:.4f}\")\n",
    "\n",
    "# get average of the results\n",
    "print(results)\n",
    "avg_tc_dice = sum([x[0] for x in results]) / len(results)\n",
    "avg_ec_dice = sum([x[1] for x in results]) / len(results)\n",
    "avg_wt_dice = sum([x[2] for x in results]) / len(results)\n",
    "avg_dice_score_main = sum([x[3] for x in results]) / len(results)\n",
    "avg_mean_iou = sum([x[4] for x in results]) / len(results)\n",
    "\n",
    "print(\n",
    "    f\"Average Scores - Dice Score Main: {avg_dice_score_main:.4f}, Mean IoU: {avg_mean_iou:.4f}, Tumor Core: {avg_tc_dice:.4f}, Enhancing Tumor: {avg_ec_dice:.4f}, Whole Tumor: {avg_wt_dice:.4f}\")\n",
    "\n",
    "# # get the IQR of the results\n",
    "\n",
    "tc_dice_values = [x[0] for x in results]\n",
    "ec_dice_values = [x[1] for x in results]\n",
    "wt_dice_values = [x[2] for x in results]\n",
    "dice_score_main_values = [x[3] for x in results]\n",
    "mean_iou_values = [x[4] for x in results]\n",
    "\n",
    "print(\n",
    "    f\"IQR of Tumor Core Dice: {np.percentile(tc_dice_values, 75) - np.percentile(tc_dice_values, 25)}\")\n",
    "print(\n",
    "    f\"IQR of Enhancing Tumor Dice: {np.percentile(ec_dice_values, 75) - np.percentile(ec_dice_values, 25)}\")\n",
    "print(\n",
    "    f\"IQR of Whole Tumor Dice: {np.percentile(wt_dice_values, 75) - np.percentile(wt_dice_values, 25)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
