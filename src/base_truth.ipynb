{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# take the model and test 5 images in in validation set\n",
    "\n",
    "import torch\n",
    "from utils.load_data import BrainDataset, get_data_loaders\n",
    "from architecture.shared_model import load_trained_model, All_view, evaluate_dice_scores, class_dice, arrange_img, dice_coef, mean_iou, DLUNet\n",
    "import random\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# get data\n",
    "train_loader, val_loader, test_loader = get_data_loaders(\"../data\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T17:18:55.104064Z",
     "start_time": "2025-05-24T17:18:54.923516Z"
    }
   },
   "source": [
    "# from architecture.shared_model import DLUNet, ReASPP3, load_trained_model\n",
    "# 1. First create a fresh model instance\n",
    "\n",
    "model = DLUNet(in_channels=4)\n",
    "model = torch.load(\n",
    "    # \"../mlruns/820203924686178493/40d84b246dd1475a93e8fb5c244ae452/artifacts/checkpoints/dlu_net_model_epoch_15.pth\"\n",
    "    \"../model/base_model/dlu_net_model_epoch_10.pth\",\n",
    "# weights_only=False,\n",
    "    map_location=device\n",
    ")\n",
    "\n",
    "# model.load_state_dict(state_dict['state_dict'])\n",
    "\n",
    "\n",
    "# 5. Set model to evaluation mode\n",
    "model.eval()\n",
    "print(\"Model loaded successfully and set to evaluation mode\")"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 16\u001B[39m\n\u001B[32m      5\u001B[39m model = torch.load(\n\u001B[32m      6\u001B[39m     \u001B[38;5;66;03m# \"../mlruns/820203924686178493/40d84b246dd1475a93e8fb5c244ae452/artifacts/checkpoints/dlu_net_model_epoch_15.pth\"\u001B[39;00m\n\u001B[32m      7\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m../model/base_model/dlu_net_model_epoch_10.pth\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# weights_only=False,\u001B[39;00m\n\u001B[32m      9\u001B[39m     map_location=device\n\u001B[32m     10\u001B[39m )\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# model.load_state_dict(state_dict['state_dict'])\u001B[39;00m\n\u001B[32m     13\u001B[39m \n\u001B[32m     14\u001B[39m \n\u001B[32m     15\u001B[39m \u001B[38;5;66;03m# 5. Set model to evaluation mode\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43meval\u001B[49m()\n\u001B[32m     17\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mModel loaded successfully and set to evaluation mode\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mAttributeError\u001B[39m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Get a sample batch from the validation loader\n",
    "# next() retrieves the first item from the iterator created by iter(val_loader)\n",
    "# iter() creates an iterator from val_loader which is likely a DataLoader object\n",
    "# This gets one batch of data containing both images and masks\n",
    "import matplotlib.pyplot as plt\n",
    "val_images, val_masks = next(iter(test_loader))\n",
    "print(f\"Batch shape - Images: {val_images.shape}, Masks: {val_masks.shape}\")\n",
    "\n",
    "\n",
    "# Select a random sample from the batch\n",
    "random_idx = random.randint(0, val_images.shape[0]-1)\n",
    "\n",
    "\n",
    "print(random_idx)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get the first sample\n",
    "    sample_image = val_images[random_idx:random_idx + 1].to(device)\n",
    "    sample_mask = val_masks[random_idx:random_idx + 1].to(device)\n",
    "\n",
    "    # Get prediction\n",
    "    prediction = model(sample_image)\n",
    "    thresholded_pred = (prediction > 0.2).float()\n",
    "\n",
    "    # Use the prediction directly for dice calculation instead of calling evaluate_dice_scores\n",
    "    tc_dice = class_dice(prediction, sample_mask, 2).item()\n",
    "    ec_dice = class_dice(prediction, sample_mask, 3).item()\n",
    "    wt_dice = class_dice(prediction, sample_mask, 4).item()\n",
    "\n",
    "    print(\n",
    "        f\"Sample Dice Scores - Tumor Core: {tc_dice:.4f}, Enhancing Tumor: {ec_dice:.4f}, Whole Tumor: {wt_dice:.4f}\")\n",
    "\n",
    "# Visualize the prediction vs ground truth\n",
    "\n",
    "# Convert tensors to the right format for visualization\n",
    "sample_image_np = sample_image.cpu().numpy().transpose(\n",
    "    0, 2, 3, 1)  # [B,C,H,W] -> [B,H,W,C]\n",
    "sample_mask_np = sample_mask.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "pred_np = thresholded_pred.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "# Use the visualization functions\n",
    "GT, Pre, TC, EC, WT = arrange_img(\n",
    "    torch.from_numpy(sample_image_np),\n",
    "    torch.from_numpy(sample_mask_np),\n",
    "    torch.from_numpy(pred_np)\n",
    ")\n",
    "\n",
    "# Convert tensors to numpy for matplotlib if needed\n",
    "if isinstance(GT, torch.Tensor):\n",
    "    GT = GT.numpy()\n",
    "if isinstance(Pre, torch.Tensor):\n",
    "    Pre = Pre.numpy()\n",
    "if isinstance(TC, torch.Tensor):\n",
    "    TC = TC.numpy()\n",
    "if isinstance(EC, torch.Tensor):\n",
    "    EC = EC.numpy()\n",
    "if isinstance(WT, torch.Tensor):\n",
    "    WT = WT.numpy()\n",
    "\n",
    "# Display the results\n",
    "fig, ax = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "ax[0, 0].imshow(GT)\n",
    "ax[0, 0].set_title('Ground Truth', fontsize=15)\n",
    "ax[0, 0].axis(\"off\")\n",
    "\n",
    "ax[0, 1].imshow(Pre)\n",
    "ax[0, 1].set_title('Prediction', fontsize=15)\n",
    "ax[0, 1].axis(\"off\")\n",
    "\n",
    "ax[0, 2].imshow(TC)\n",
    "ax[0, 2].set_title(f'Tumor Core: {tc_dice:.4f}', fontsize=15)\n",
    "ax[0, 2].axis(\"off\")\n",
    "\n",
    "ax[1, 0].imshow(EC)\n",
    "ax[1, 0].set_title(f'Enhancing Tumor: {ec_dice:.4f}', fontsize=15)\n",
    "ax[1, 0].axis(\"off\")\n",
    "\n",
    "ax[1, 1].imshow(WT)\n",
    "ax[1, 1].set_title(f'Whole Tumor: {wt_dice:.4f}', fontsize=15)\n",
    "ax[1, 1].axis(\"off\")\n",
    "\n",
    "# Display original MRI (first channel)\n",
    "ax[1, 2].imshow(sample_image_np[0, :, :, 0], cmap='gray')\n",
    "ax[1, 2].set_title('Original MRI (Channel 0)', fontsize=15)\n",
    "ax[1, 2].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def evaluate_model(model, val_loader):\n",
    "    \"\"\"\n",
    "    Evaluate model on validation data.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_dice = 0\n",
    "    total_iou = 0\n",
    "    total_class_dice = {2: 0, 3: 0, 4: 0}\n",
    "    num_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Calculate metrics\n",
    "            dice = dice_coef(outputs, masks)\n",
    "            iou = mean_iou(outputs, masks)\n",
    "\n",
    "            class_dices = {\n",
    "                2: class_dice(outputs, masks, 2),\n",
    "                3: class_dice(outputs, masks, 3),\n",
    "                4: class_dice(outputs, masks, 4)\n",
    "            }\n",
    "\n",
    "            total_dice += dice.item()\n",
    "            total_iou += iou.item()\n",
    "            for i in [2, 3, 4]:\n",
    "                total_class_dice[i] += class_dices[i].item()\n",
    "\n",
    "            num_batches += 1\n",
    "\n",
    "    # Calculate mean metrics\n",
    "    mean_metrics = {\n",
    "        \"dice_coef\": float(total_dice / num_batches),\n",
    "        \"mean_iou\": float(total_iou / num_batches),\n",
    "        \"class_dice\": {\n",
    "            \"c2\": float(total_class_dice[2] / num_batches),\n",
    "            \"c3\": float(total_class_dice[3] / num_batches),\n",
    "            \"c4\": float(total_class_dice[4] / num_batches)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(mean_metrics)\n",
    "    \n",
    "evaluate_model(model, test_loader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
